{"0": {
    "doc": "Tools and credits",
    "title": "Generalist tool for ML",
    "content": "Marcelle . Marcelle is a modular open source toolkit for programming interactive machine learning applications. Marcelle is built around components embedding computation and interaction that can be composed to form reactive machine learning pipelines and custom user interfaces. This architecture enables rapid prototyping and extension. Marcelle can be used to build interfaces to Python scripts, and it provides flexible data stores to facilitate collaboration between machine learning experts, designers and end users. Jules FranÃ§oise, Baptiste Caramiaux, TÃ©o Sanchez. Marcelle: Composing Interactive Machine Learning Workflows and Interfaces. Annual ACM Symposium on User Interface Software and Technology (UIST â€™21), Oct 2021, Virtual. DOI: 10.1145/3472749.3474734. PDF . Wekinator . The Wekinator is free, open source software that allows anyone to use machine learning to build new musical instruments, gestural game controllers, computer vision or computer listening systems, and more. The Wekinator allows users to build new interactive systems by demonstrating human actions and computer responses, instead of writing programming code. Fiebrink, R., &amp; Cook, P. R. (2010, January). The Wekinator: a system for real-time, interactive machine learning in music. In Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht) (Vol. 3, pp. 2-1). ml-lib . ml-lib is a library of machine learning externals for Max and Pure Data. ml-lib is primarily based on the Gesture Recognition Toolkit by Nick Gillian ml-lib is designed to work on a variety of platforms including OS X, Windows, Linux, on Intel and ARM architectures. The goal of ml-lib is to provide a simple, consistent interface to a wide range of machine learning techniques in Max and Pure Data. Bullock, J., &amp; Momeni, A. (2015, May). Ml. lib: robust, cross-platform, open-source machine learning for max and pure data. In NIME (pp. 265-270). nn~ . nn~ is a Pd or Max/MSP external object that allows to load and run neural networks in real-time. It is based on the PyTorch C++ API and can load any network that can be exported from PyTorch to TorchScript. It can be used to load RAVE models. ",
    "url": "/docs/credits/#generalist-tool-for-ml",
    
    "relUrl": "/docs/credits/#generalist-tool-for-ml"
  },"1": {
    "doc": "Tools and credits",
    "title": "Specialized ML tools (audio, text, othersâ€¦)",
    "content": "RAVE . Rave is a variational autoencoder for fast and high-quality neural audio synthesis developed by Antoine Caillon and Philippe Esling from IRCAM. Caillon, A., &amp; Esling, P. (2021). RAVE: A variational autoencoder for fast and high-quality neural audio synthesis. arXiv preprint arXiv:2111.05011. LangChain . LangChain is a framework for developing applications powered by language models. It enables applications that: . | Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.) . | Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.) . | . Flucoma . Combination of digital signal processing and machine learning. Connection to SuperCollider, PureData and Max. ",
    "url": "/docs/credits/#specialized-ml-tools-audio-text-others",
    
    "relUrl": "/docs/credits/#specialized-ml-tools-audio-text-others"
  },"2": {
    "doc": "Tools and credits",
    "title": "Generalist tools for audio and visual programming",
    "content": "Pure Data . Pure Data (or just â€œPdâ€) is an open source visual programming language for multimedia. Pure Data allows you to create and manipulate audio systems using visual elements, rather than writing code. Think of it as building with virtual blocks â€“ simply connect them together to design your unique audio setups. Plug Data . plugdata is a free/open-source visual programming environment based on pure-data. It is available for a wide range of operating systems, and can be used both as a standalone app, or as a VST3, LV2, CLAP or AU plugin. We recommend using Plug Data rather than Pure Data, as it provides a more user-friendly interface. SuperCollider . SuperCollider is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. It is free and open source software available for Windows, macOS, and Linux. P5hs Processing Nannou . Visual Creative Coding, Coupling between Audio and Visual . TouchDesigner . Node-based visual programming language and environment for real-time interaction with different media . ",
    "url": "/docs/credits/#generalist-tools-for-audio-and-visual-programming",
    
    "relUrl": "/docs/credits/#generalist-tools-for-audio-and-visual-programming"
  },"3": {
    "doc": "Tools and credits",
    "title": "More AIArtists tools and ressources",
    "content": "AIartists . ",
    "url": "/docs/credits/#more-aiartists-tools-and-ressources",
    
    "relUrl": "/docs/credits/#more-aiartists-tools-and-ressources"
  },"4": {
    "doc": "Tools and credits",
    "title": "Tools and credits",
    "content": " ",
    "url": "/docs/credits/",
    
    "relUrl": "/docs/credits/"
  },"5": {
    "doc": "Directions and useful infos",
    "title": "How to go to the Wavelab ?",
    "content": "Address . Wavelab, BarerstraÃŸe 19, 80333 MÃ¼nchen . Copy Address . ",
    "url": "/docs/directions/#how-to-go-to-the-wavelab-",
    
    "relUrl": "/docs/directions/#how-to-go-to-the-wavelab-"
  },"6": {
    "doc": "Directions and useful infos",
    "title": "Arrival methods",
    "content": "Bicycle . | Bicycle parking is available. | . Public Transportation . | Subway: KÃ¶nigsplatz or Odeonsplatz stations. | Tram: Karolinenplatz stop. | City-Railway: Stachus or Hauptbahnhof stations (then a 10-minute walk). | . ",
    "url": "/docs/directions/#arrival-methods",
    
    "relUrl": "/docs/directions/#arrival-methods"
  },"7": {
    "doc": "Directions and useful infos",
    "title": "Route to Wavelab from BarerstraÃŸe 19",
    "content": ". | Enter through the left side entrance of the building and proceed to the green courtyard. Look for and follow the red HMTM signs. | Walk along the building until you see a wheelchair ramp and stairs on your right. This leads into the Wavelab. | The door to Wavelab is not automatic. Please ring the bell labeled Wavelab to gain entry. | . ",
    "url": "/docs/directions/#route-to-wavelab-from-barerstra%C3%9Fe-19",
    
    "relUrl": "/docs/directions/#route-to-wavelab-from-barerstraÃŸe-19"
  },"8": {
    "doc": "Directions and useful infos",
    "title": "Important Advice",
    "content": "The Wavelab is situated in the rear building of the Israeli Consulate General (GKI), which has a high security level. When visiting, please keep the following in mind: . | Avoid lingering or standing on the sidewalk at BarerstraÃŸe 19; move close to the tram stop if you need to make a phone call or are waiting for someone. | If approached by GKI security personnel, promptly identify yourself as a guest of the Wavelab. | . ",
    "url": "/docs/directions/#important-advice",
    
    "relUrl": "/docs/directions/#important-advice"
  },"9": {
    "doc": "Directions and useful infos",
    "title": "Directions and useful infos",
    "content": " ",
    "url": "/docs/directions/",
    
    "relUrl": "/docs/directions/"
  },"10": {
    "doc": "Group feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": ". | An implementation of a factor oracle for Pure Data | Omax | Dicy2 and its video tutorials | Festival on co-improvisation | Valerio Velardo Youtube channel on machine learning for music | Artemi-Maria Gioti was also interested in machine-artist communication and gave a talk in the last Wintersemester for AICA and here is also an interview where she talks about some implementation details. | . Assayag, G., &amp; Dubnov, S. (2004). Using factor oracles for machine improvisation. Soft Computing, 8(9), 604-610. Wilson, A. J. (2016). factorOracle: an Extensible Max External for Investigating Applications of the Factor Oracle Automaton in Real-Time Music Improvisation. Nika, J., Chemillier, M., &amp; Assayag, G. (2017). Improtek: introducing scenarios into human-computer music improvisation. Computers in Entertainment (CIE), 14(2), 1-27. Dubnov, S., Assayag, G., &amp; Cont, A. (2007). Audio oracle: A new algorithm for fast learning of audio structures. In Proceedings of International Computer Music Conference (ICMC). ICMA. ",
    "url": "/docs/feedback/group_feedback/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/docs/feedback/group_feedback/#group-a--human-machine-co-improvisation"
  },"11": {
    "doc": "Group feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": ". | How to use Stable diffusion locally | Automatic111 webGUI : AUTOMATIC111 also provides an API so it should be possible to . | Make a history of prompts via some GUI, for example a Python application | Send parts of the history as prompt to Stable Diffusion | Receive and display the image and save the pair (image, prompt) into the archive/history | . | . You can also access Stable Diffusion and other image generators via an API but if it does not run on your machine you have to pay for it. ",
    "url": "/docs/feedback/group_feedback/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/docs/feedback/group_feedback/#group-b--collaborative-visual-story-telling"
  },"12": {
    "doc": "Group feedback",
    "title": "Group C : Emotion recognition for personalized recommendation",
    "content": ". | FER | DeepFace | FaceWork : a critical gamification of facial recognition. You can read more about the artist Kyle McDonald that is familiar with the relation between AI and faces. | . ",
    "url": "/docs/feedback/group_feedback/#group-c--emotion-recognition-for-personalized-recommendation",
    
    "relUrl": "/docs/feedback/group_feedback/#group-c--emotion-recognition-for-personalized-recommendation"
  },"13": {
    "doc": "Group feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": ". | Gaussian splatting for 3D modelling of items | A tutorial for learning embeddings of (simplistic) fashion item images. | PoseNet for estimating poses | . Gu, X., Wong, Y., Shou, L., Peng, P., Chen, G., &amp; Kankanhalli, M. S. (2018). Multi-modal and multi-domain embedding learning for fashion retrieval and analysis. IEEE Transactions on Multimedia, 21(6), 1524-1537. ",
    "url": "/docs/feedback/group_feedback/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/docs/feedback/group_feedback/#group-d--virtual-archives-of-clothing-artefacts"
  },"14": {
    "doc": "Group feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": ". | Audio-to-text : DeepSpeech (can run locally) or Whisper (API calls); | Question processing : Langchain or https://www.llamaindex.ai/. My guess is that you will necessary have to call an API for this part; | Have a look to Chat with data and other tutorials. Local Large Language Models exist (llama.cpp) but are heavy to be supported by an embed system like a Raspberry Pi (it is already too heavy for my computer); | Text-to-speech : I donâ€™t know much about it but have a look to Mozilla TTS, Google TTS, and coqui-ai TTS. | . ",
    "url": "/docs/feedback/group_feedback/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/docs/feedback/group_feedback/#group-e--ai-augmented-audio-guide"
  },"15": {
    "doc": "Group feedback",
    "title": "Group feedback",
    "content": "Raw notes (sent by email) . ",
    "url": "/docs/feedback/group_feedback/",
    
    "relUrl": "/docs/feedback/group_feedback/"
  },"16": {
    "doc": "About",
    "title": "AI in culture and arts - project workshop",
    "content": ". ",
    "url": "/#ai-in-culture-and-arts---project-workshop",
    
    "relUrl": "/#ai-in-culture-and-arts---project-workshop"
  },"17": {
    "doc": "About",
    "title": "ðŸ“° Announcements",
    "content": "11.01.2023 - Get ready! The third and last bloc of the course will take place on the 5th, 6th, and 7th of February 2024. You will be asked to demonstrate your MVP to our team of experts. 11.01.2023 - ðŸ“¹ Please upload your minimal viable prototype (MVP) video before the 26th January 2024, 23:59. 11.01.2024 - We watched your proof of concept videos! Congrats to all for your progress. Please find our feedback for the next phase. 10.11.2023 - The presentation slides of the first bloc are now available. ",
    "url": "/#-announcements",
    
    "relUrl": "/#-announcements"
  },"18": {
    "doc": "About",
    "title": "Table of contents",
    "content": ". | What is AICA? | What is the project workshop ? | Tutorials | Evaluation and ECTS | Credits and attributions | License | . ",
    "url": "/#table-of-contents",
    
    "relUrl": "/#table-of-contents"
  },"19": {
    "doc": "About",
    "title": "What is AICA?",
    "content": "The Digitization College â€œArtificial Intelligence in Culture and Artsâ€ (AICA) aims to equip students at the University of Music and Performing Arts Munich (HMTM) and Hochschule MÃ¼nchen University of Applied Sciences (HM) with necessary skills to impact AI innovations in the creative and cultural industries. Learn more about AICA . ",
    "url": "/#what-is-aica",
    
    "relUrl": "/#what-is-aica"
  },"20": {
    "doc": "About",
    "title": "What is the project workshop ?",
    "content": "The AICA Project Workshop will be hosted at the Wavelab, in the Winter Semester 2023/2024 starting November 2023. This course will teach you how to build and apply AI and machine learning for the cultural and artistic domains. You will develop your own project at the interface of AI in art and culture, spanning from an intelligent or interactive tool, an artistic performance, or anything in between that applies to the creative and cultural industries. You will form a team with students from HM and HMTM with complementary expertise: computer science, data science, design, music, theater, or cultural management. You will be accompanied on site by technology and culture experts, and coached with Agile software development practices. ",
    "url": "/#what-is-the-project-workshop-",
    
    "relUrl": "/#what-is-the-project-workshop-"
  },"21": {
    "doc": "About",
    "title": "Tutorials",
    "content": "This website provides a large range of tutorials and ressources, organized by topic and difficulty. Feel free to use and adapt any of the ressources to implement your project ! . Tutorial overview . ",
    "url": "/#tutorials",
    
    "relUrl": "/#tutorials"
  },"22": {
    "doc": "About",
    "title": "Evaluation and ECTS",
    "content": "You will earn 6 ECTS for the validation of the course. The evaluation will be based on two deliverables: . | A 10-page group term paper describing the development of the project; | A group presentation of the project; | . We highly encourage students to extend and capitalize on their projects to derive a bachelor or master thesis. ",
    "url": "/#evaluation-and-ects",
    
    "relUrl": "/#evaluation-and-ects"
  },"23": {
    "doc": "About",
    "title": "Credits and attributions",
    "content": "The tutorial are based on several open-source tools and libraries developed by talented researchers and developers. Without them, this course would not be possible. Discover all of them in section Credits and attributions. ",
    "url": "/#credits-and-attributions",
    
    "relUrl": "/#credits-and-attributions"
  },"24": {
    "doc": "About",
    "title": "License",
    "content": "The new teaching material (tutorials and code) created for the course is available under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). Each tool and library demonstrated in the tutorials is subject to its own license. ",
    "url": "/#license",
    
    "relUrl": "/#license"
  },"25": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"26": {
    "doc": "Group feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": "Progresses . | Implemented the second half of the pipeline: the factor oracle is now able to generate new notes from the sequence learned. These notes are played by a minimal synthesizer. You almost have a proof of concept of the system. | . Next steps for the PoC . | Crash test the factorOracle: try to really co-impprovise with the machine. Does it stay locked in loops? What if you train with longer musical phrases? Please document your observations. | Improve the audio synthesis: To improve your minimal synthesizer, learn about ADSR envelope and ways to implement it in PureData, learn about the timber quality of a saxophone and how to reimplement it. In addition, please have a look to audio style transfer using RAVE and nn~ on tutorial #3. | . ",
    "url": "/docs/feedback/office_hours_summary/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/docs/feedback/office_hours_summary/#group-a--human-machine-co-improvisation"
  },"27": {
    "doc": "Group feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": "Progresses . | The group successfuly use the openAI API to generate prompts from story fragments and generate an image from the prompt (using DALL-E). | The narrative of the project was discussed as it does not clearly match the cultural and creative industries but rather gamify the text-to-image recreative practice. We discussed to reframe the project as a tool for amateur storyboard creation. | The implementation was assigned according to goup memberâ€™s technical abilities. Moritz will learn about front-end development while Felix will tackle the back-end devlopment using the Flask python framework. | . Next steps for the PoC . | The narrative of the project is still unclear. Please interview potential users to understand how they would use and comprehend your project | Design and sketch usersâ€™ interactions (as a story board?) | The proof of concept should be a working application where users enter a prompt and receive an image. | . ",
    "url": "/docs/feedback/office_hours_summary/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/docs/feedback/office_hours_summary/#group-b--collaborative-visual-story-telling"
  },"28": {
    "doc": "Group feedback",
    "title": "Group C : Music generation from movements and dance",
    "content": "Progresses . | The group should possess all necessary hardware (piezoelectric sensors, armband, Arduino, bread board etc.) | The group successfuly assign roles for the project. Fabian is in charge of sound synthesis with SuperCollider. Matthias implemented the projectâ€™s architecture and is in charge of the hardware. Marius is in charge of estimating bpm using recurrent neural network. | The program architecture is clear and functionnal. | The group succesfully applied a peak detection algorithm on fake data. | . Next steps for the PoC . | Stream the piezoelectric sensor data to the computer | Try a simple LSTM (recurrent neural network) to estimate the bpm (or localization) from the piezoelectric sensor data | Test the entire pipeline, from sensor to sound synthesis | . ",
    "url": "/docs/feedback/office_hours_summary/#group-c--music-generation-from-movements-and-dance",
    
    "relUrl": "/docs/feedback/office_hours_summary/#group-c--music-generation-from-movements-and-dance"
  },"29": {
    "doc": "Group feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": "Progresses . | The group decided to focus an interactive â€œmirrorâ€ for visitors to try moving clothing artefacts. An alternative direction was to let users â€œlook aroundâ€ a still clothing artefacts by tracking peopleâ€™s head. This direction was discarded. | The group did a technological watch of proprietary solutions for pose estimation from images. None of them are both free and in real-time. | The group successfully used BlendArMocap in Blender to extract a skeleton from a video stream. The pose estimation is very slow. | The group successfully infered a skeleton from a single frame using Googleâ€™s mediapipe. It can potentially speed up the | . Next steps for the PoC . | Model any clothing artefact and map skeleton joints to the clothing artefact. | . ",
    "url": "/docs/feedback/office_hours_summary/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/docs/feedback/office_hours_summary/#group-d--virtual-archives-of-clothing-artefacts"
  },"30": {
    "doc": "Group feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": "Progresses . | The group successfully called text-to-speech, speech-to-text and conversational bots from the OpenAI API. | The work was divided between group members. Julian would focus on the back-end development with Flask. Philip will focus on the front-end development in HTML, CSS, and JS (audio recording and playback). Scientific tutors will help to conncect the front-end and back-end. | . Next steps for the PoC . | Sketch and prototype the userâ€™s interaction. Keep it simple (no voice detection) and reflect on the relevance of the features for a museum visitor. | Implement the front-end of the application with HTML, CSS, and JS. | Implement the back-end of the application with Flask. | Connect the front-end and back-end. | . ",
    "url": "/docs/feedback/office_hours_summary/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/docs/feedback/office_hours_summary/#group-e--ai-augmented-audio-guide"
  },"31": {
    "doc": "Group feedback",
    "title": "Group feedback",
    "content": " ",
    "url": "/docs/feedback/office_hours_summary/",
    
    "relUrl": "/docs/feedback/office_hours_summary/"
  },"32": {
    "doc": "PoC video feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": "Great job for the PoC video! Please move on with the improvements you described. ",
    "url": "/docs/feedback/poc_feedback/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/docs/feedback/poc_feedback/#group-a--human-machine-co-improvisation"
  },"33": {
    "doc": "PoC video feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": "If the image generation from a story works in python, it has yet to be an interactive application that people can easily use. Please refer to our last office hour feedback for future improvements. Remember to work on the utility and application scope of your system; last time we talked, it still needed to be clarified. Good luck! . ",
    "url": "/docs/feedback/poc_feedback/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/docs/feedback/poc_feedback/#group-b--collaborative-visual-story-telling"
  },"34": {
    "doc": "PoC video feedback",
    "title": "Group C : Music generation from movements and dance",
    "content": "The video is not fully clear, but it seems to work and you clearly made progress! Your personal reflections on the results would be appreciated for the next video/bloc. Is the interaction you are designing engaging for users? Improvements evoked during our last office hour are still relevant. The real milestone would be to try a life-size installation! Good luck! . ",
    "url": "/docs/feedback/poc_feedback/#group-c--music-generation-from-movements-and-dance",
    
    "relUrl": "/docs/feedback/poc_feedback/#group-c--music-generation-from-movements-and-dance"
  },"35": {
    "doc": "PoC video feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": "The physics of your clothing item is not bad at all! However, the video is a bit long, and only two body points were mapped. Hence, it was unclear if the system was really working. Please map the entire skeleton to your clothing model so we can reflect better on possible improvements: is the bottleneck the skeleton extraction, the clothing model, or something else? Good luck! . ",
    "url": "/docs/feedback/poc_feedback/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/docs/feedback/poc_feedback/#group-d--virtual-archives-of-clothing-artefacts"
  },"36": {
    "doc": "PoC video feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": "Great job for implementing a user interface. Improvements can now be made in the generation speed and interface design. Do not hesitate to reach out to us for help on these topics. Good luck! . ",
    "url": "/docs/feedback/poc_feedback/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/docs/feedback/poc_feedback/#group-e--ai-augmented-audio-guide"
  },"37": {
    "doc": "PoC video feedback",
    "title": "PoC video feedback",
    "content": " ",
    "url": "/docs/feedback/poc_feedback/",
    
    "relUrl": "/docs/feedback/poc_feedback/"
  },"38": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": "Coming soonâ€¦ . | 9:00 AM | 9:30 AM | 10:00 AM | 10:30 AM | 11:00 AM | 11:30 AM | 12:00 PM | 12:30 PM | 1:00 PM | 1:30 PM | 2:00 PM | 2:30 PM | 3:00 PM | 3:30 PM | 4:00 PM | 4:30 PM | 5:00 PM | 5:30 PM | . | ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"39": {
    "doc": "Schedule",
    "title": "Monday",
    "content": ". | Lecture 9:30 AMâ€“10:30 AM 150 Wheeler | Section 11:30 AMâ€“12:30 PM 310 Soda | Office Hours 12:30 PMâ€“2:00 PM 271 Soda | . | ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"40": {
    "doc": "Schedule",
    "title": "Tuesday",
    "content": "| ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"41": {
    "doc": "Schedule",
    "title": "Wednesday",
    "content": ". | Lecture 9:30 AMâ€“10:30 AM 150 Wheeler | Section 11:30 AMâ€“12:30 PM 310 Soda | Office Hours 12:30 PMâ€“2:00 PM 271 Soda | . | ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"42": {
    "doc": "Schedule",
    "title": "Thursday",
    "content": "| ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"43": {
    "doc": "Schedule",
    "title": "Friday",
    "content": ". | Lecture 9:30 AMâ€“10:30 AM 150 Wheeler | Section 11:30 AMâ€“12:30 PM 310 Soda | Office Hours 12:30 PMâ€“2:00 PM 271 Soda | . | . --> ",
    "url": "/docs/schedule/",
    
    "relUrl": "/docs/schedule/"
  },"44": {
    "doc": "Instructors",
    "title": "Scientific instructors",
    "content": "Scientific instructors prepared the technical content hosted on this website. They can guide you through the tutorials and your final project implementation. Dr. Benedikt ZÃ¶nnchen (HM - MUC.DAI) . Dr. TÃ©o Sanchez (HM - MUC.DAI) . ",
    "url": "/docs/staff/#scientific-instructors",
    
    "relUrl": "/docs/staff/#scientific-instructors"
  },"45": {
    "doc": "Instructors",
    "title": "Art and culture instructors",
    "content": "Artistic instructors can guide you through the artistic and cultural aspects of your project. Helena Held (HMTM) . ",
    "url": "/docs/staff/#art-and-culture-instructors",
    
    "relUrl": "/docs/staff/#art-and-culture-instructors"
  },"46": {
    "doc": "Instructors",
    "title": "AICA project leader",
    "content": "Dr. Esther Fee Feichtner (HMTM) . ",
    "url": "/docs/staff/#aica-project-leader",
    
    "relUrl": "/docs/staff/#aica-project-leader"
  },"47": {
    "doc": "Instructors",
    "title": "Lecturers and consultants",
    "content": "External artists and experts will give lectures and be available on-site to advice you on your project. Holger Neumann . Katja Littow . Nina Stemberger . Prof. Sylvia Rothe . ",
    "url": "/docs/staff/#lecturers-and-consultants",
    
    "relUrl": "/docs/staff/#lecturers-and-consultants"
  },"48": {
    "doc": "Instructors",
    "title": "Teaching assistants",
    "content": "Students from HM and HMTM will also be present on-site to help organizing the course. David Kosian (HMTM) . David Helm (HM) . ",
    "url": "/docs/staff/#teaching-assistants",
    
    "relUrl": "/docs/staff/#teaching-assistants"
  },"49": {
    "doc": "Instructors",
    "title": "Instructors",
    "content": " ",
    "url": "/docs/staff/",
    
    "relUrl": "/docs/staff/"
  }
}
