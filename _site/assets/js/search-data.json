{"0": {
    "doc": "Directions and useful infos",
    "title": "MUC.DAI",
    "content": "Address . Munich Center for Digital Sciences and AI (MUC.DAI), Infanteriestra√üe 13, 80797 M√ºnchen . Copy Address . ",
    "url": "/project-workshop/content/directions/#mucdai",
    
    "relUrl": "/content/directions/#mucdai"
  },"1": {
    "doc": "Directions and useful infos",
    "title": "Arrival methods",
    "content": "Bicycle . | Bicycle parking is available on the campus. | . Public Transportation . | Subway: U2, Josephsplatz or Hohenzollernplatz stations. | Tram and bus: Leonrodplatz . | . Where to have lunch near MUC.DAI? . | Birdie: The closest restaurant (1min by foot), propose a faily special and Focaccias. | La Stella Doro M√ºnchen: One of the closest snack (6min by foot), Pizzas mainly. | Student‚Äôs MENSA Lothstra√üe: The closest student‚Äôs MENSA (13min by foot). Might be busy at lunchtime. | You can also find snacks on Dachauer Stra√üe but be aware that they might be busy at lunchtime. Please don‚Äôt be late in the afternoon. | . ",
    "url": "/project-workshop/content/directions/#arrival-methods",
    
    "relUrl": "/content/directions/#arrival-methods"
  },"2": {
    "doc": "Directions and useful infos",
    "title": "Wavelab",
    "content": "Address . Wavelab, Barerstra√üe 19, 80333 M√ºnchen . Copy Address . ",
    "url": "/project-workshop/content/directions/#wavelab",
    
    "relUrl": "/content/directions/#wavelab"
  },"3": {
    "doc": "Directions and useful infos",
    "title": "Arrival methods",
    "content": "Bicycle . | Bicycle parking is available. | . Public Transportation . | Subway: K√∂nigsplatz or Odeonsplatz stations. | Tram: Karolinenplatz stop. | City-Railway: Stachus or Hauptbahnhof stations (then a 10-minute walk). | . Route to Wavelab from Barerstra√üe 19 . | Enter through the left side entrance of the building and proceed to the green courtyard. Look for and follow the red HMTM signs. | Walk along the building until you see a wheelchair ramp and stairs on your right. This leads into the Wavelab. | The door to Wavelab is not automatic. Please ring the bell labeled Wavelab to gain entry. | . Important Advice . The Wavelab is situated in the rear building of the Israeli Consulate General (GKI), which has a high security level. When visiting, please keep the following in mind: . | Avoid lingering or standing on the sidewalk at Barerstra√üe 19; move close to the tram stop if you need to make a phone call or are waiting for someone. | If approached by GKI security personnel, promptly identify yourself as a guest of the Wavelab. | . Where to have lunch near the Wavelab? . | Wais K√ºche: One of the closest place (6min by foot). It is a small Vietnamese canteen. | Student‚Äôs MENSA Arcisstra√üe: The closest student‚Äôs MENSA (7min by foot). Might be busy at lunchtime. | Other snacks and restaurant (mostly Indian and Vietnamese food) can be found on further North on Barer Stra√üe, in front of the Neue Pinakothek. | . ",
    "url": "/project-workshop/content/directions/#arrival-methods-1",
    
    "relUrl": "/content/directions/#arrival-methods-1"
  },"4": {
    "doc": "Directions and useful infos",
    "title": "Directions and useful infos",
    "content": "The course will take place in two different locations: Munich Center for Digital Sciences and Artificial Intelligence (MUC.DAI) and the Wavelab. Below you will find the addresses and directions to both locations. ",
    "url": "/project-workshop/content/directions/",
    
    "relUrl": "/content/directions/"
  },"5": {
    "doc": "Group feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": ". | An implementation of a factor oracle for Pure Data | Omax | Dicy2 and its video tutorials | Festival on co-improvisation | Valerio Velardo Youtube channel on machine learning for music | Artemi-Maria Gioti was also interested in machine-artist communication and gave a talk in the last Wintersemester for AICA and here is also an interview where she talks about some implementation details. | . Assayag, G., &amp; Dubnov, S. (2004). Using factor oracles for machine improvisation. Soft Computing, 8(9), 604-610. Wilson, A. J. (2016). factorOracle: an Extensible Max External for Investigating Applications of the Factor Oracle Automaton in Real-Time Music Improvisation. Nika, J., Chemillier, M., &amp; Assayag, G. (2017). Improtek: introducing scenarios into human-computer music improvisation. Computers in Entertainment (CIE), 14(2), 1-27. Dubnov, S., Assayag, G., &amp; Cont, A. (2007). Audio oracle: A new algorithm for fast learning of audio structures. In Proceedings of International Computer Music Conference (ICMC). ICMA. ",
    "url": "/project-workshop/content/feedback/group_feedback/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/content/feedback/group_feedback/#group-a--human-machine-co-improvisation"
  },"6": {
    "doc": "Group feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": ". | How to use Stable diffusion locally | Automatic111 webGUI : AUTOMATIC111 also provides an API so it should be possible to . | Make a history of prompts via some GUI, for example a Python application | Send parts of the history as prompt to Stable Diffusion | Receive and display the image and save the pair (image, prompt) into the archive/history | . | . You can also access Stable Diffusion and other image generators via an API but if it does not run on your machine you have to pay for it. ",
    "url": "/project-workshop/content/feedback/group_feedback/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/content/feedback/group_feedback/#group-b--collaborative-visual-story-telling"
  },"7": {
    "doc": "Group feedback",
    "title": "Group C : Emotion recognition for personalized recommendation",
    "content": ". | FER | DeepFace | FaceWork : a critical gamification of facial recognition. You can read more about the artist Kyle McDonald that is familiar with the relation between AI and faces. | . ",
    "url": "/project-workshop/content/feedback/group_feedback/#group-c--emotion-recognition-for-personalized-recommendation",
    
    "relUrl": "/content/feedback/group_feedback/#group-c--emotion-recognition-for-personalized-recommendation"
  },"8": {
    "doc": "Group feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": ". | Gaussian splatting for 3D modelling of items | A tutorial for learning embeddings of (simplistic) fashion item images. | PoseNet for estimating poses | . Gu, X., Wong, Y., Shou, L., Peng, P., Chen, G., &amp; Kankanhalli, M. S. (2018). Multi-modal and multi-domain embedding learning for fashion retrieval and analysis. IEEE Transactions on Multimedia, 21(6), 1524-1537. ",
    "url": "/project-workshop/content/feedback/group_feedback/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/content/feedback/group_feedback/#group-d--virtual-archives-of-clothing-artefacts"
  },"9": {
    "doc": "Group feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": ". | Audio-to-text : DeepSpeech (can run locally) or Whisper (API calls); | Question processing : Langchain or https://www.llamaindex.ai/. My guess is that you will necessary have to call an API for this part; | Have a look to Chat with data and other tutorials. Local Large Language Models exist (llama.cpp) but are heavy to be supported by an embed system like a Raspberry Pi (it is already too heavy for my computer); | Text-to-speech : I don‚Äôt know much about it but have a look to Mozilla TTS, Google TTS, and coqui-ai TTS. | . ",
    "url": "/project-workshop/content/feedback/group_feedback/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/content/feedback/group_feedback/#group-e--ai-augmented-audio-guide"
  },"10": {
    "doc": "Group feedback",
    "title": "Group feedback",
    "content": "Raw notes (sent by email) . ",
    "url": "/project-workshop/content/feedback/group_feedback/",
    
    "relUrl": "/content/feedback/group_feedback/"
  },"11": {
    "doc": "About",
    "title": "AI in culture and arts - project workshop",
    "content": " ",
    "url": "/project-workshop/#ai-in-culture-and-arts---project-workshop",
    
    "relUrl": "/#ai-in-culture-and-arts---project-workshop"
  },"12": {
    "doc": "About",
    "title": "üì∞ Announcements",
    "content": "02.09.2024 - The 2nd edition of the project workshop will be starting over in the Winter Semester 2024. Please enroll to the course in Subscription section. ",
    "url": "/project-workshop/#-announcements",
    
    "relUrl": "/#-announcements"
  },"13": {
    "doc": "About",
    "title": "Table of contents",
    "content": ". | What is AICA? | What is the project workshop ? | Provisional schedule | Evaluation and ECTS | Tools and tutorials | License | . ",
    "url": "/project-workshop/#table-of-contents",
    
    "relUrl": "/#table-of-contents"
  },"14": {
    "doc": "About",
    "title": "What is AICA?",
    "content": "The Digitization College ‚ÄúArtificial Intelligence in Culture and Arts‚Äù (AICA) aims to equip students at the University of Music and Performing Arts Munich (HMTM) and Hochschule M√ºnchen University of Applied Sciences (HM) with necessary skills to impact AI innovations in the creative and cultural industries. Learn more about AICA . ",
    "url": "/project-workshop/#what-is-aica",
    
    "relUrl": "/#what-is-aica"
  },"15": {
    "doc": "About",
    "title": "What is the project workshop ?",
    "content": "The AICA Project Workshop will be hosted at the Wavelab, in the Winter Semester 2024/2025 starting early November 2024. This course will teach you how to build and apply AI and machine learning for the cultural and artistic domains. You will develop your own project at the interface of AI in art and culture, spanning from an intelligent or interactive tool, an artistic performance, or anything in between that applies to the creative and cultural industries. You will form a team with students from HM and HMTM with complementary expertise: computer science, data science, design, music, theater, or cultural management. You will be accompanied on site by technology and culture experts, and coached with Agile software development practices. ",
    "url": "/project-workshop/#what-is-the-project-workshop-",
    
    "relUrl": "/#what-is-the-project-workshop-"
  },"16": {
    "doc": "About",
    "title": "Provisional schedule",
    "content": "Block 1: . | 6th of November 2024 at MUC.DAI (Infanteriestra√üe 13, 80797 M√ºnchen, Room N.017) | 7th of November 2024 at MUC.DAI (Infanteriestra√üe 13, 80797 M√ºnchen, Room N.017) | . Block 2: . | 11th of December 2024 at the Wavelab (Barerstra√üe 19, 80333 M√ºnchen) | 12th of December 2024 at the Wavelab (Barerstra√üe 19, 80333 M√ºnchen) | . Block 3: . | 8th of January 2025 at the Wavelab (Barerstra√üe 19, 80333 M√ºnchen) | 9th of January 2025 at the Wavelab (Barerstra√üe 19, 80333 M√ºnchen) | . Final event: . | 30th of January 2025 at MUC.DAI (Infanteriestra√üe 13, 80797 M√ºnchen, Room N.017) | . ",
    "url": "/project-workshop/#provisional-schedule",
    
    "relUrl": "/#provisional-schedule"
  },"17": {
    "doc": "About",
    "title": "Evaluation and ECTS",
    "content": "You will earn 6 ECTS for the validation of the course. The evaluation will be based on 100 points, distributed as follows: . | 30 points for the careful completion of the assignements between blocks; | 20 points for the final presentation, on the 30th of January 2025: oral presence, slides quality, and clarity of the outcomes and dissemination; | 20 points for significance of the project outcomes and their potential impact on the cultural and artistic domains; | 20 points for the relevance and significiance of the project‚Äôs dissemination; | 10 points for dedication and attitude: attendance, proactivity, team spirit, and respect. Additional penalties may be applied in case of deliberate misconduct that would harm the team or the course. | . The 100 points will then be converted to the German grading system according to the table below: . | Points | German system | Description | . | 90 - 100 | 1.0 | Very good (Sehr gut) | . | 85 - 89 | 1.3 | Very good (Sehr gut) | . | 80 - 84 | 1.7 | Good (Gut) | . | 75 - 79 | 2.0 | Good (Gut) | . | 70 - 74 | 2.3 | Satisfactory (Befriedigend) | . | 65 - 69 | 2.7 | Satisfactory (Befriedigend) | . | 60 - 64 | 3.0 | Satisfactory (Befriedigend) | . | 55 - 59 | 3.3 | Sufficient (Ausreichend) | . | 50 - 54 | 3.7 | Sufficient (Ausreichend) | . | Below 50 | 5.0 | Fail (Nicht ausreichend) | . We encourage students to extend and capitalize on their projects to derive a bachelor or master thesis. ",
    "url": "/project-workshop/#evaluation-and-ects",
    
    "relUrl": "/#evaluation-and-ects"
  },"18": {
    "doc": "About",
    "title": "Tools and tutorials",
    "content": "Many open-source tools and libraries developed by talented researchers and developers will help you implement your project without re-inventing the wheel. Discover all of them in section Tools. Please also check the relevant tutorials from our last tech crash course on human-AI interaction. ",
    "url": "/project-workshop/#tools-and-tutorials",
    
    "relUrl": "/#tools-and-tutorials"
  },"19": {
    "doc": "About",
    "title": "License",
    "content": "The new teaching material created for the course is available under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). Each tool or library demonstrated in the tutorials is subject to its own license. ",
    "url": "/project-workshop/#license",
    
    "relUrl": "/#license"
  },"20": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "/project-workshop/",
    
    "relUrl": "/"
  },"21": {
    "doc": "Group feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": "Progresses . | Implemented the second half of the pipeline: the factor oracle is now able to generate new notes from the sequence learned. These notes are played by a minimal synthesizer. You almost have a proof of concept of the system. | . Next steps for the PoC . | Crash test the factorOracle: try to really co-impprovise with the machine. Does it stay locked in loops? What if you train with longer musical phrases? Please document your observations. | Improve the audio synthesis: To improve your minimal synthesizer, learn about ADSR envelope and ways to implement it in PureData, learn about the timber quality of a saxophone and how to reimplement it. In addition, please have a look to audio style transfer using RAVE and nn~ on tutorial #3. | . ",
    "url": "/project-workshop/content/feedback/office_hours_summary/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/content/feedback/office_hours_summary/#group-a--human-machine-co-improvisation"
  },"22": {
    "doc": "Group feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": "Progresses . | The group successfuly use the openAI API to generate prompts from story fragments and generate an image from the prompt (using DALL-E). | The narrative of the project was discussed as it does not clearly match the cultural and creative industries but rather gamify the text-to-image recreative practice. We discussed to reframe the project as a tool for amateur storyboard creation. | The implementation was assigned according to goup member‚Äôs technical abilities. Moritz will learn about front-end development while Felix will tackle the back-end devlopment using the Flask python framework. | . Next steps for the PoC . | The narrative of the project is still unclear. Please interview potential users to understand how they would use and comprehend your project | Design and sketch users‚Äô interactions (as a story board?) | The proof of concept should be a working application where users enter a prompt and receive an image. | . ",
    "url": "/project-workshop/content/feedback/office_hours_summary/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/content/feedback/office_hours_summary/#group-b--collaborative-visual-story-telling"
  },"23": {
    "doc": "Group feedback",
    "title": "Group C : Music generation from movements and dance",
    "content": "Progresses . | The group should possess all necessary hardware (piezoelectric sensors, armband, Arduino, bread board etc.) | The group successfuly assign roles for the project. Fabian is in charge of sound synthesis with SuperCollider. Matthias implemented the project‚Äôs architecture and is in charge of the hardware. Marius is in charge of estimating bpm using recurrent neural network. | The program architecture is clear and functionnal. | The group succesfully applied a peak detection algorithm on fake data. | . Next steps for the PoC . | Stream the piezoelectric sensor data to the computer | Try a simple LSTM (recurrent neural network) to estimate the bpm (or localization) from the piezoelectric sensor data | Test the entire pipeline, from sensor to sound synthesis | . ",
    "url": "/project-workshop/content/feedback/office_hours_summary/#group-c--music-generation-from-movements-and-dance",
    
    "relUrl": "/content/feedback/office_hours_summary/#group-c--music-generation-from-movements-and-dance"
  },"24": {
    "doc": "Group feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": "Progresses . | The group decided to focus an interactive ‚Äúmirror‚Äù for visitors to try moving clothing artefacts. An alternative direction was to let users ‚Äúlook around‚Äù a still clothing artefacts by tracking people‚Äôs head. This direction was discarded. | The group did a technological watch of proprietary solutions for pose estimation from images. None of them are both free and in real-time. | The group successfully used BlendArMocap in Blender to extract a skeleton from a video stream. The pose estimation is very slow. | The group successfully infered a skeleton from a single frame using Google‚Äôs mediapipe. It can potentially speed up the | . Next steps for the PoC . | Model any clothing artefact and map skeleton joints to the clothing artefact. | . ",
    "url": "/project-workshop/content/feedback/office_hours_summary/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/content/feedback/office_hours_summary/#group-d--virtual-archives-of-clothing-artefacts"
  },"25": {
    "doc": "Group feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": "Progresses . | The group successfully called text-to-speech, speech-to-text and conversational bots from the OpenAI API. | The work was divided between group members. Julian would focus on the back-end development with Flask. Philip will focus on the front-end development in HTML, CSS, and JS (audio recording and playback). Scientific tutors will help to conncect the front-end and back-end. | . Next steps for the PoC . | Sketch and prototype the user‚Äôs interaction. Keep it simple (no voice detection) and reflect on the relevance of the features for a museum visitor. | Implement the front-end of the application with HTML, CSS, and JS. | Implement the back-end of the application with Flask. | Connect the front-end and back-end. | . ",
    "url": "/project-workshop/content/feedback/office_hours_summary/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/content/feedback/office_hours_summary/#group-e--ai-augmented-audio-guide"
  },"26": {
    "doc": "Group feedback",
    "title": "Group feedback",
    "content": " ",
    "url": "/project-workshop/content/feedback/office_hours_summary/",
    
    "relUrl": "/content/feedback/office_hours_summary/"
  },"27": {
    "doc": "PoC video feedback",
    "title": "Group A : Human-machine co-improvisation",
    "content": "Great job for the PoC video! Please move on with the improvements you described. ",
    "url": "/project-workshop/content/feedback/poc_feedback/#group-a--human-machine-co-improvisation",
    
    "relUrl": "/content/feedback/poc_feedback/#group-a--human-machine-co-improvisation"
  },"28": {
    "doc": "PoC video feedback",
    "title": "Group B : Collaborative visual story-telling",
    "content": "If the image generation from a story works in python, it has yet to be an interactive application that people can easily use. Please refer to our last office hour feedback for future improvements. Remember to work on the utility and application scope of your system; last time we talked, it still needed to be clarified. Good luck! . ",
    "url": "/project-workshop/content/feedback/poc_feedback/#group-b--collaborative-visual-story-telling",
    
    "relUrl": "/content/feedback/poc_feedback/#group-b--collaborative-visual-story-telling"
  },"29": {
    "doc": "PoC video feedback",
    "title": "Group C : Music generation from movements and dance",
    "content": "The video is not fully clear, but it seems to work and you clearly made progress! Your personal reflections on the results would be appreciated for the next video/bloc. Is the interaction you are designing engaging for users? Improvements evoked during our last office hour are still relevant. The real milestone would be to try a life-size installation! Good luck! . ",
    "url": "/project-workshop/content/feedback/poc_feedback/#group-c--music-generation-from-movements-and-dance",
    
    "relUrl": "/content/feedback/poc_feedback/#group-c--music-generation-from-movements-and-dance"
  },"30": {
    "doc": "PoC video feedback",
    "title": "Group D : Virtual archives of clothing artefacts",
    "content": "The physics of your clothing item is not bad at all! However, the video is a bit long, and only two body points were mapped. Hence, it was unclear if the system was really working. Please map the entire skeleton to your clothing model so we can reflect better on possible improvements: is the bottleneck the skeleton extraction, the clothing model, or something else? Good luck! . ",
    "url": "/project-workshop/content/feedback/poc_feedback/#group-d--virtual-archives-of-clothing-artefacts",
    
    "relUrl": "/content/feedback/poc_feedback/#group-d--virtual-archives-of-clothing-artefacts"
  },"31": {
    "doc": "PoC video feedback",
    "title": "Group E : AI-augmented audio guide",
    "content": "Great job for implementing a user interface. Improvements can now be made in the generation speed and interface design. Do not hesitate to reach out to us for help on these topics. Good luck! . ",
    "url": "/project-workshop/content/feedback/poc_feedback/#group-e--ai-augmented-audio-guide",
    
    "relUrl": "/content/feedback/poc_feedback/#group-e--ai-augmented-audio-guide"
  },"32": {
    "doc": "PoC video feedback",
    "title": "PoC video feedback",
    "content": " ",
    "url": "/project-workshop/content/feedback/poc_feedback/",
    
    "relUrl": "/content/feedback/poc_feedback/"
  },"33": {
    "doc": "Provisional schedule",
    "title": "Provisional schedule",
    "content": "Please find the provisional schedule of the course below. The schedule is subject to change in the course of the semester. ",
    "url": "/project-workshop/content/program/",
    
    "relUrl": "/content/program/"
  },"34": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": "Coming soon‚Ä¶ . &lt;li class=\"schedule-day \"&gt; &lt;h2 class=\"schedule-header no_anchor\"&gt;23th of April&lt;/h2&gt; &lt;ul class=\"schedule-events\" style=\"height: 1400px\"&gt; &lt;li class=\"schedule-event brief\" style=\"top: 140px; height: 70px;\"&gt; &lt;div class=\"name\"&gt;Brief : Module introduction&lt;/div&gt; &lt;div class=\"time\"&gt;10:00‚Äì10:30&lt;/div&gt; &lt;/li&gt; &lt;li class=\"schedule-event lecture\" style=\"top: 210px; height: 210px;\"&gt; &lt;div class=\"name\"&gt;Lecture : Introduction to machine learning&lt;/div&gt; &lt;div class=\"time\"&gt;10:30‚Äì12:00&lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; . &lt;/ul&gt; &lt;/div&gt; . ‚Äì&gt; . ",
    "url": "/project-workshop/content/schedule/",
    
    "relUrl": "/content/schedule/"
  },"35": {
    "doc": "Instructors",
    "title": "AICA project leader",
    "content": "Mariya Dzhimova (HMTM) . ",
    "url": "/project-workshop/content/staff/#aica-project-leader",
    
    "relUrl": "/content/staff/#aica-project-leader"
  },"36": {
    "doc": "Instructors",
    "title": "Scientific instructors",
    "content": "Scientific instructors prepared the technical content hosted on this website. They can guide you through the tutorials and your final project implementation. Dr. Benedikt Z√∂nnchen (HM - MUC.DAI) . Dr. T√©o Sanchez (HM - MUC.DAI) . ",
    "url": "/project-workshop/content/staff/#scientific-instructors",
    
    "relUrl": "/content/staff/#scientific-instructors"
  },"37": {
    "doc": "Instructors",
    "title": "Art and culture instructors",
    "content": "Artistic instructors can guide you through the artistic and cultural aspects of your project. Helena Held (HMTM) . ",
    "url": "/project-workshop/content/staff/#art-and-culture-instructors",
    
    "relUrl": "/content/staff/#art-and-culture-instructors"
  },"38": {
    "doc": "Instructors",
    "title": "Lecturers and consultants",
    "content": "External artists and experts will give lectures and be available on-site to advice you on your project. Christoph Weber . Dr. Esther Fee Reinhardt . Ilja Mirsky . Jule Schr√∂der . Lenka Hamosova . ",
    "url": "/project-workshop/content/staff/#lecturers-and-consultants",
    
    "relUrl": "/content/staff/#lecturers-and-consultants"
  },"39": {
    "doc": "Instructors",
    "title": "Teaching assistants",
    "content": "Students from HM and HMTM will also be present on-site to help organizing the course. Tanja Huber (HM) . ",
    "url": "/project-workshop/content/staff/#teaching-assistants",
    
    "relUrl": "/content/staff/#teaching-assistants"
  },"40": {
    "doc": "Instructors",
    "title": "Instructors",
    "content": " ",
    "url": "/project-workshop/content/staff/",
    
    "relUrl": "/content/staff/"
  },"41": {
    "doc": "Subscription",
    "title": "Enroll now! üí•",
    "content": "Please follow these steps to enroll in the class. ",
    "url": "/project-workshop/content/subscription/#enroll-now-",
    
    "relUrl": "/content/subscription/#enroll-now-"
  },"42": {
    "doc": "Subscription",
    "title": "1. Express your interest",
    "content": "Express your interest to Dr. T√©o Sanchez directly (teo [dot] sanchez [at] hm [dot] edu) with a short motivation statement. ",
    "url": "/project-workshop/content/subscription/#1-express-your-interest",
    
    "relUrl": "/content/subscription/#1-express-your-interest"
  },"43": {
    "doc": "Subscription",
    "title": "2. Sign up on the administrative platform of your university",
    "content": "To validate the class and get the credits, you need to sign up to the class on the administrative platform of your university. Hochschule M√ºnchen University of applied sciences . Sign up on Nine Hochschule f√ºr Musik und Theater M√ºnchen . Sign up on eCampus ",
    "url": "/project-workshop/content/subscription/#2-sign-up-on-the-administrative-platform-of-your-university",
    
    "relUrl": "/content/subscription/#2-sign-up-on-the-administrative-platform-of-your-university"
  },"44": {
    "doc": "Subscription",
    "title": "3. Sign up to the moodle platform",
    "content": "The moodle platform is open to both HM and HMTM students. It is not an administrative platform, but tool to exchange between students and teachers. It is meant to gather all institutional emails, submit and collect assigments, and publish grades. Sign up on Moodle NB: You can subscribe with and without HM credentials. Just select DFN-AAI/eduGAIN if you are not an HM student. ",
    "url": "/project-workshop/content/subscription/#3-sign-up-to-the-moodle-platform",
    
    "relUrl": "/content/subscription/#3-sign-up-to-the-moodle-platform"
  },"45": {
    "doc": "Subscription",
    "title": "Subscription",
    "content": " ",
    "url": "/project-workshop/content/subscription/",
    
    "relUrl": "/content/subscription/"
  },"46": {
    "doc": "Tools",
    "title": "Generalist tool for ML",
    "content": "Marcelle . Marcelle is a modular open source toolkit for programming interactive machine learning applications. Marcelle is built around components embedding computation and interaction that can be composed to form reactive machine learning pipelines and custom user interfaces. This architecture enables rapid prototyping and extension. Marcelle can be used to build interfaces to Python scripts, and it provides flexible data stores to facilitate collaboration between machine learning experts, designers and end users. Jules Fran√ßoise, Baptiste Caramiaux, T√©o Sanchez. Marcelle: Composing Interactive Machine Learning Workflows and Interfaces. Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äô21), Oct 2021, Virtual. DOI: 10.1145/3472749.3474734. PDF . Wekinator . The Wekinator is free, open source software that allows anyone to use machine learning to build new musical instruments, gestural game controllers, computer vision or computer listening systems, and more. The Wekinator allows users to build new interactive systems by demonstrating human actions and computer responses, instead of writing programming code. Fiebrink, R., &amp; Cook, P. R. (2010, January). The Wekinator: a system for real-time, interactive machine learning in music. In Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht) (Vol. 3, pp. 2-1). ml-lib . ml-lib is a library of machine learning externals for Max and Pure Data. ml-lib is primarily based on the Gesture Recognition Toolkit by Nick Gillian ml-lib is designed to work on a variety of platforms including OS X, Windows, Linux, on Intel and ARM architectures. The goal of ml-lib is to provide a simple, consistent interface to a wide range of machine learning techniques in Max and Pure Data. Bullock, J., &amp; Momeni, A. (2015, May). Ml. lib: robust, cross-platform, open-source machine learning for max and pure data. In NIME (pp. 265-270). nn~ . nn~ is a Pd or Max/MSP external object that allows to load and run neural networks in real-time. It is based on the PyTorch C++ API and can load any network that can be exported from PyTorch to TorchScript. It can be used to load RAVE models. ",
    "url": "/project-workshop/content/tools/#generalist-tool-for-ml",
    
    "relUrl": "/content/tools/#generalist-tool-for-ml"
  },"47": {
    "doc": "Tools",
    "title": "Specialized ML tools (audio, text, others‚Ä¶)",
    "content": "RAVE . Rave is a variational autoencoder for fast and high-quality neural audio synthesis developed by Antoine Caillon and Philippe Esling from IRCAM. Caillon, A., &amp; Esling, P. (2021). RAVE: A variational autoencoder for fast and high-quality neural audio synthesis. arXiv preprint arXiv:2111.05011. LangChain . LangChain is a framework for developing applications powered by language models. It enables applications that: . | Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.) . | Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.) . | . Flucoma . Combination of digital signal processing and machine learning. Connection to SuperCollider, PureData and Max. ",
    "url": "/project-workshop/content/tools/#specialized-ml-tools-audio-text-others",
    
    "relUrl": "/content/tools/#specialized-ml-tools-audio-text-others"
  },"48": {
    "doc": "Tools",
    "title": "Generalist tools for audio and visual programming",
    "content": "Pure Data . Pure Data (or just ‚ÄúPd‚Äù) is an open source visual programming language for multimedia. Pure Data allows you to create and manipulate audio systems using visual elements, rather than writing code. Think of it as building with virtual blocks ‚Äì simply connect them together to design your unique audio setups. Plug Data . plugdata is a free/open-source visual programming environment based on pure-data. It is available for a wide range of operating systems, and can be used both as a standalone app, or as a VST3, LV2, CLAP or AU plugin. We recommend using Plug Data rather than Pure Data, as it provides a more user-friendly interface. SuperCollider . SuperCollider is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. It is free and open source software available for Windows, macOS, and Linux. P5hs Processing Nannou . Visual Creative Coding, Coupling between Audio and Visual . TouchDesigner . Node-based visual programming language and environment for real-time interaction with different media . ",
    "url": "/project-workshop/content/tools/#generalist-tools-for-audio-and-visual-programming",
    
    "relUrl": "/content/tools/#generalist-tools-for-audio-and-visual-programming"
  },"49": {
    "doc": "Tools",
    "title": "More AIArtists tools and ressources",
    "content": "AIartists . ",
    "url": "/project-workshop/content/tools/#more-aiartists-tools-and-ressources",
    
    "relUrl": "/content/tools/#more-aiartists-tools-and-ressources"
  },"50": {
    "doc": "Tools",
    "title": "Tools",
    "content": " ",
    "url": "/project-workshop/content/tools/",
    
    "relUrl": "/content/tools/"
  }
}
