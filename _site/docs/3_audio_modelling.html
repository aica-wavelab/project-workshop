<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"><style type="text/css"> .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external):nth-child(6) > .nav-list-link { display: block; font-weight: 600; text-decoration: none; background-image: linear-gradient(-90deg, #ebedf5 0%, rgba(235, 237, 245, 0.8) 80%, rgba(235, 237, 245, 0) 100%); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(6) > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(6) > .nav-list { display: block; } .site-nav > .nav-category-list > .nav-list-item > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-category-list > .nav-list-item > .nav-list { display: block; }</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JFBL1M5RX8"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-JFBL1M5RX8', { 'anonymize_ip': true }); </script> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/assets/images/favicon.ico" type="image/x-icon"><title>Audio modelling and synthesis with neural networks | AICA project workshop</title><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Audio modelling and synthesis with neural networks" /><meta name="author" content="Téo Sanchez, Benedikt Zönnchen" /><meta property="og:locale" content="en_US" /><meta name="description" content="Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab" /><meta property="og:description" content="Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab" /><link rel="canonical" href="http://localhost:4000/docs/3_audio_modelling" /><meta property="og:url" content="http://localhost:4000/docs/3_audio_modelling" /><meta property="og:site_name" content="AICA project workshop" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Audio modelling and synthesis with neural networks" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Téo Sanchez, Benedikt Zönnchen"},"description":"Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab","headline":"Audio modelling and synthesis with neural networks","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logos/aica_logo.png"},"name":"Téo Sanchez, Benedikt Zönnchen"},"url":"http://localhost:4000/docs/3_audio_modelling"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-logo" role="img" aria-label="AICA project workshop"></div>AICA project workshop </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">About</a><li class="nav-list-item"><a href="/docs/directions/" class="nav-list-link">Directions and useful infos</a><li class="nav-list-item"><a href="/docs/tutorial/" class="nav-list-link">Tutorial overview</a><li class="nav-list-item"><a href="/docs/1_intro_ml" class="nav-list-link">1. Introduction to machine learning</a><li class="nav-list-item"><a href="/docs/2_mapping_demonstration" class="nav-list-link">2. Mapping by demonstration</a><li class="nav-list-item"><a href="/docs/3_audio_modelling" class="nav-list-link">3. Audio modelling and synthesis with neural networks</a><li class="nav-list-item"><a href="/docs/4_embed_cultural_archives" class="nav-list-link">4. Embed and explore cultural archives</a><li class="nav-list-item"><a href="/docs/5_language_model" class="nav-list-link">5. Language model for domain-specific application</a><li class="nav-list-item"><a href="/docs/staff/" class="nav-list-link">Instructors</a><li class="nav-list-item"><a href="/docs/credits/" class="nav-list-link">Tools and credits</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search AICA project workshop" aria-label="Search AICA project workshop" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://www.wavelab.io/aica/" class="site-button" > AICA Digitization College </a></ul></nav></div><div class="main-content-wrap"><div id="main-content" class="main-content"><main><h1 class="no_toc" id="audio-modelling-and-synthesis-with-neural-networks"> <a href="#audio-modelling-and-synthesis-with-neural-networks" class="anchor-heading" aria-labelledby="audio-modelling-and-synthesis-with-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Audio modelling and synthesis with neural networks</h1><p>Neural networks prove to be a powerful tool to model and synthesize audio signals in the waveform domain. This chapter will teach you how to train and use a real-time neural synthesizer using the <a href="https://github.com/acids-ircam/RAVE">Real-Time Audio Variational autoEncoder (RAVE)</a> model developed by the <a href="https://acids.ircam.fr/">ACIDS team at Ircam</a>, and include it in your Pure Data patch with <a href="https://acids-ircam.github.io/nn_tilde/">nn~</a>.</p><hr /><h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of contents</h2><ol id="markdown-toc"><li><a href="#audio-modelling-and-synthesis-with-pre-trained-neural-networks" id="markdown-toc-audio-modelling-and-synthesis-with-pre-trained-neural-networks">Audio modelling and synthesis with pre-trained neural networks</a><li><a href="#train-your-model-from-your-own-corpus-of-sound" id="markdown-toc-train-your-model-from-your-own-corpus-of-sound">Train your model from your own corpus of sound</a></ol><hr /><h2 id="audio-modelling-and-synthesis-with-pre-trained-neural-networks"> <a href="#audio-modelling-and-synthesis-with-pre-trained-neural-networks" class="anchor-heading" aria-labelledby="audio-modelling-and-synthesis-with-pre-trained-neural-networks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Audio modelling and synthesis with pre-trained neural networks</h2><p>Recent advances in deep learning have enabled the development of neural networks that can model and synthesize audio signals in the waveform domain. After training on corpus of sound, the trained model can be used to generate new audio signals, or to transform existing ones.</p><p>In particular, the RAVE model is a variational autoencoder for fast and high-quality neural audio synthesis developed by Antoine Caillon and Philippe Esling from the ACIDS team in IRCAM.</p><p>Trained RAVE models can be loaded in Pure Data or Max/MSP (paying alternative to Pd) using the <code class="language-plaintext highlighter-rouge">nn~</code> external. Let’s have a look to their demonstration.</p><iframe width="100%" height="420" src="https://www.youtube.com/embed/dMZs04TzxUI" title="Realtime Neural Audio Synthesis - RAVE + nn~ #1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>You can learn more about the specificity of the RAVE architecture on the tutorial below:</p><iframe width="100%" height="420" src="https://www.youtube.com/embed/o09BSf9zP-0" title="IRCAM Tutorials / Rave and nn~" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>You can learn more about the RAVE model on the <a href="https://github.com/acids-ircam/RAVE">official github repository</a>. Please find a demo of audio transfer in Pure Data using <a href="https://acids-ircam.github.io/nn_tilde/"><code class="language-plaintext highlighter-rouge">nn~</code></a> and a pre-trained model in the link below:</p><p><a href="https://github.com/aica-wavelab/aica-project-workshop/tree/main/3_neural_synthesis" class="btn" target="_blank">Audio style transfer in Pd</a></p><p>Other pre-trained models are available on <a href="https://acids-ircam.github.io/rave_models_download">here</a> and <a href="https://iil.is/news/ravemodels">here</a>.</p><h2 id="train-your-model-from-your-own-corpus-of-sound"> <a href="#train-your-model-from-your-own-corpus-of-sound" class="anchor-heading" aria-labelledby="train-your-model-from-your-own-corpus-of-sound"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Train your model from your own corpus of sound</h2><p>Training a RAVE model on your own corpus of sound is possible but computationally expensive. We cannot provide you with a GPU (Graphical Processing Unit), used to train artificial neural network. However, you can use the following Google Colab written by <a href="https://github.com/moiseshorta">hexorcismos</a>, which is a computational notebook that runs on GPU hosted by Google:</p><p><a href="https://colab.research.google.com/drive/1ih-gv1iHEZNuGhHPvCHrleLNXvooQMvI?usp=sharing" class="btn" target="_blank">Training a RAVE model on Google Colab</a></p></main><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><div class="logo-container"><footer> <img src="/assets/images/logos/hm_logo.png" alt="Logo HM"> <img src="/assets/images/logos/mucdai_logo.jpg" alt="Logo MUC.DAI"> <img src="/assets/images/logos/hmtm_logo.png" alt="Logo HMTM"> <img src="/assets/images/logos/wavelab_logo.jpg" alt="Logo Wavelab"> <img src="/assets/images/logos/bidt_logo.png" alt="Logo BIDT"></footer></div><style> .logo-container img { filter: grayscale(100%); width: 100px; margin-right: 50px; } .logo-container img:last-child { margin-right: 0; }</style><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.6/dist/mermaid.min.js"></script> <script> var config = {} ; mermaid.initialize(config); window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid')); </script>
