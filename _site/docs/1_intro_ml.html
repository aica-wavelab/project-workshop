<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"><style type="text/css"> .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external):nth-child(4) > .nav-list-link { display: block; font-weight: 600; text-decoration: none; background-image: linear-gradient(-90deg, #ebedf5 0%, rgba(235, 237, 245, 0.8) 80%, rgba(235, 237, 245, 0) 100%); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(4) > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:nth-child(4) > .nav-list { display: block; } .site-nav > .nav-category-list > .nav-list-item > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-category-list > .nav-list-item > .nav-list { display: block; }</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JFBL1M5RX8"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-JFBL1M5RX8', { 'anonymize_ip': true }); </script> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/assets/images/favicon.ico" type="image/x-icon"><title>Introduction to machine learning | AICA project workshop</title><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Introduction to machine learning" /><meta name="author" content="Téo Sanchez, Benedikt Zönnchen" /><meta property="og:locale" content="en_US" /><meta name="description" content="Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab" /><meta property="og:description" content="Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab" /><link rel="canonical" href="http://localhost:4000/docs/1_intro_ml" /><meta property="og:url" content="http://localhost:4000/docs/1_intro_ml" /><meta property="og:site_name" content="AICA project workshop" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Introduction to machine learning" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Téo Sanchez, Benedikt Zönnchen"},"description":"Artificial Intelligence in Culture and Arts (AICA): Tools and tutorials for the project workshop at the Wavelab","headline":"Introduction to machine learning","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logos/aica_logo.png"},"name":"Téo Sanchez, Benedikt Zönnchen"},"url":"http://localhost:4000/docs/1_intro_ml"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-logo" role="img" aria-label="AICA project workshop"></div>AICA project workshop </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">About</a><li class="nav-list-item"><a href="/docs/directions/" class="nav-list-link">Directions and useful infos</a><li class="nav-list-item"><a href="/docs/tutorial/" class="nav-list-link">Tutorial overview</a><li class="nav-list-item"><a href="/docs/1_intro_ml" class="nav-list-link">1. Introduction to machine learning</a><li class="nav-list-item"><a href="/docs/2_mapping_demonstration" class="nav-list-link">2. Mapping by demonstration</a><li class="nav-list-item"><a href="/docs/3_audio_modelling" class="nav-list-link">3. Audio modelling and synthesis with neural networks</a><li class="nav-list-item"><a href="/docs/4_embed_cultural_archives" class="nav-list-link">4. Embed and explore cultural archives</a><li class="nav-list-item"><a href="/docs/5_language_model" class="nav-list-link">5. Language model for domain-specific application</a><li class="nav-list-item"><a href="/docs/staff/" class="nav-list-link">Instructors</a><li class="nav-list-item"><a href="/docs/credits/" class="nav-list-link">Tools and credits</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search AICA project workshop" aria-label="Search AICA project workshop" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://www.wavelab.io/aica/" class="site-button" > AICA Digitization College </a></ul></nav></div><div class="main-content-wrap"><div id="main-content" class="main-content"><main><h1 class="no_toc" id="introduction-to-machine-learning"> <a href="#introduction-to-machine-learning" class="anchor-heading" aria-labelledby="introduction-to-machine-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Introduction to machine learning</h1><p>This chapter will teach you foundational concepts of machine learning (ML) through hands-on turorials. The first three chapters only use interactive applications, no programming skills are required. The fourth chapter reiterates the same concepts using programming tools that prevail in the ML industry, namely the Python programming language and dedicated ML libraries. Lastly, the fifth section provides ressources to develop your on web-based interactive ML application, using the <a href="https://www.marcelle.dev">Marcelle</a> toolkit.</p><blockquote class="note-title"><p>Tips</p><p>We recommend to all attendants to follow the first four sections.</p></blockquote><hr /><h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of contents</h2><ol id="markdown-toc"><li><a href="#train-your-first-image-classifier" id="markdown-toc-train-your-first-image-classifier">Train your first image classifier</a><li><a href="#the-development-cycle-of-ml" id="markdown-toc-the-development-cycle-of-ml">The development cycle of ML</a><ol><li><a href="#data-collection" id="markdown-toc-data-collection">Data collection</a><li><a href="#training" id="markdown-toc-training">Training</a><li><a href="#testing" id="markdown-toc-testing">Testing</a><li><a href="#deployment" id="markdown-toc-deployment">Deployment</a></ol><li><a href="#train-your-model-in-python" id="markdown-toc-train-your-model-in-python">Train your model in Python</a><li><a href="#create-your-own-interactive-ml-web-application" id="markdown-toc-create-your-own-interactive-ml-web-application">Create your own interactive ML web application</a></ol><hr /><h2 id="train-your-first-image-classifier"> <a href="#train-your-first-image-classifier" class="anchor-heading" aria-labelledby="train-your-first-image-classifier"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Train your first image classifier</h2><p>Have you ever trained a machine learning model ? If not, this is the right place to start. First of all, what is a machine learning?</p><blockquote class="note-title"><p>Definition</p><p>Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize from examples and thus perform tasks without explicit instructions.</p></blockquote><p>In other words, machine learning (ML) part of the field of AI but its specificity lies in the fact that algorithms are learning from data. To give you a concrete example, let’s train your first image classifier from images collected with your webcam and using the application below.</p><p><a href="/marcelle/ml-webcam" class="btn" target="_blank">Train my first image classifier! </a></p><p>In this application, you can activate the <code class="language-plaintext highlighter-rouge">webcam</code> of your laptop on the left side of the screen. Below the <code class="language-plaintext highlighter-rouge">webcam</code>, you can choose a <code class="language-plaintext highlighter-rouge">label</code> to be associated with the images you will collect. Once the <code class="language-plaintext highlighter-rouge">label</code> selected, click on the button <code class="language-plaintext highlighter-rouge">hold to collect</code> to collect images with the corresponding <code class="language-plaintext highlighter-rouge">label</code>. Doing so, you will see the images you collect appearing in the <code class="language-plaintext highlighter-rouge">Training set</code> in the middle of the screen. Reiterate this process for each <code class="language-plaintext highlighter-rouge">label</code> you want to collect images for.</p><p>Once you finalized the creation of your <code class="language-plaintext highlighter-rouge">Training set</code> (images + corresponding labels), you can click on the button <code class="language-plaintext highlighter-rouge">Train</code> to train your image classifier. Then, you can activate the <code class="language-plaintext highlighter-rouge">webcam</code> again and see the predictions of your image classifier in real-time in the component <code class="language-plaintext highlighter-rouge">Prediction confidence</code> on the bottom of the screen.</p><blockquote class="note-title"><p>Hints</p><p>Take the time to test the model you trained. Try to trick its predictions and see how it reacts. What data could you add to the training set to improve its predictions?</p></blockquote><p>You trained your first image classifier! Congratulations! But you don’t know much about how machine learning works… Let’s now see what’s going on under the hood of this web application.</p><h2 id="the-development-cycle-of-ml"> <a href="#the-development-cycle-of-ml" class="anchor-heading" aria-labelledby="the-development-cycle-of-ml"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The development cycle of ML</h2><p>The development of ML is a cycle composed of 4 main steps. These steps are illustrated in the application below.</p><p><a href="/marcelle/ml-vision" class="btn" target="_blank">The development cycle of ML</a></p><h3 class="note-title note-title" id="data-collection"> <a href="#data-collection" class="anchor-heading" aria-labelledby="data-collection"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data collection</h3><p>The first step of the development cycle of ML is data collection. It consists in collecting and annotating data samples that can be used by an ML algorithm to learn a mapping from inputs to outputs. In the previous example, the data samples are images collected with your webcam and the corresponding labels you provided. If pairs of input and output are provided in the training set, we talk about <strong>supervised learning</strong>. If only inputs are provided, we talk about <strong>unsupervised learning</strong>.</p><p>The data samples are usually gathered in two sets: the <strong>training set</strong> and the <strong>test set</strong>. The training set is used to train the ML model, while the test set is used to evaluate the performance of the trained model. In other words, the training set is the exemples you work on during the semester, while the test set is the final exam.</p><p>We provide various miniature image datasets that represent classification problems in engineering, medecine, and public health:</p><ul><li>miniMASK: a dataset of 3 classes of images (with masks, without masks, and with masks incorrectly worn);<li>miniROAD: a dataset of 3 classes or green, orange, and red traffic lights;<li>miniTRASH: a dataset of 3 classes of images (packaging, transparent glass, and opaque glass);<li>miniRETINA: a medical dataset of 3 classes of retinoscopic images (healthy, macular degeneration, and diabetic retinopathy);<li>miniSKIN: a medical dataset of 2 classes of dermatoscopic images (benign and malignant skin lesions);</ul><p>On the <a href="https://aica-wavelab.github.io/marcelle/ml-vision/#training"><code class="language-plaintext highlighter-rouge">Data collection</code></a> page, click on one button to select the dataset you want to work with for the rest of the tutorial.</p><blockquote class="note-title"><p>Hints</p><p>Take the time observe each images (by clicking on the thumbnails). Are the differences between each classes obvious to you?</p></blockquote><h3 id="training"> <a href="#training" class="anchor-heading" aria-labelledby="training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Training</h3><p>The training phase comprises three steps:</p><p>2.1. <strong>Features selection</strong> : in our case, we will use a pre-trained neural network called MobileNet that extract 1024 features from images. These features were learned from a large dataset of images (ImageNet) and can be used to represent any image.</p><p>2.2. <strong>Model selection</strong> : Many machine learning models exist and were developed. In our case, we will use a model called multi-layer perceptron (MLP). It is a simple artificial neural network composed of an input layer (in our case, the 1024 features from MobileNe, some hidden layers that we can choose, and an output layer (the number of classes). Two other parameters are important to set. The <strong>batchSize</strong> and the number of <strong>epochs</strong>. An artificial neural network can updates its neurons using several examples at the same time. The batch size indicates the number of images that will be used at each round to update the neurons. The number of epochs indicates the number of times the whole training set will be used to update the neurons. The higher the number of epochs, the more the model will be trained. However, if the number of epochs is too high, the model might overfit the training set and will not be able to generalize to new data. You can choose the number of hidden layers and neurons per layer, the batch size, and the number of epochs on the <a href="https://aica-wavelab.github.io/marcelle/ml-vision/#training"><code class="language-plaintext highlighter-rouge">Training</code></a> page of the application.</p><p>2.3. <strong>Training</strong> : Click on the training button to start the neural network optimization. You will then see two different learning curves appearing. The represent the losses and accuracies as a function of the number of epochs. The loss is a measure of the error between the predictions of the model and the true labels. The accuracy is the percentage of correct predictions. A validation loss and accuracy are computed using a portion of the training set that is not used for the training. If the validation loss and validation accuracy are not improving, it means that the model is overfitting the training set and that it will not generalize well to new data. In this case, you should stop the training and reflect on the parameters of the model or the data used for the task.</p><h3 id="testing"> <a href="#testing" class="anchor-heading" aria-labelledby="testing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Testing</h3><p>At this point, the model only saw the training set, eventhough it artificially splited this set into a training and validation set. To really assess the model performance, we need to compute a test accuracy on unseen images. On the <a href="https://aica-wavelab.github.io/marcelle/ml-vision/#training"><code class="language-plaintext highlighter-rouge">Testing</code></a> page of the application, you can see two <strong>confusion matrices</strong>. On the left is shown the global accuracy and a confusion matrix computed on the training set only. The rows of the confusion matrix represent the true labels (what should be predicted), while the columns represent the predicted labels. The diagonal of the matrix represents the number of correct predictions. A confusion matrix gives a finer view of which class is confused with which class. On the left, you can see the global accuracy and a confusion matrix computed on the test set only. The test accuracy is a better indicator of the model performance. If the test accuracy is much lower than the training accuracy, it means that the model is overfitting the training set and that it will not generalize well to new data.</p><blockquote class="note-title note-title"><p>Questions</p><ol><li>For the task you selected, what averaged accuracy would you obtain with a random classifer? Is the trained classifier better than a random classifier in your case?<li>What difference do you observe between the training and test accuracies? What does it mean?<li>Which classes are the most confused? Why do you think so? Among the confusions you identified, is there any would be more problematic than others in the problem selected?<li>What would you do to improve the model performance?</ol></blockquote><h3 id="deployment"> <a href="#deployment" class="anchor-heading" aria-labelledby="deployment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Deployment</h3><p>Now you trained and test a machine learning model, you can learn more about its behavior by observing its predictions on particular images. On the <a href="https://aica-wavelab.github.io/marcelle/ml-vision/#training"><code class="language-plaintext highlighter-rouge">Deployment</code></a> page of the application, you can see the predictions of the model when you click on the thumbnails of the training or test set. Machine learning models can be noisy and biased. <strong>Noisiness</strong> indicates that the model is not stable and that it can give different predictions for similar inputs (it’s unpredictably wrong). <strong>Bias</strong> indicates that the model is wrong or unfair for similar inputs (it’s always wrong in the same way). Biases in ML models can lead to discrimination as illustrated in many different controversies over the past years. These incidents are documented on a public website called <a href="https://incidentdatabase.ai/cite/37/">AI incident database</a>.</p><blockquote class="note-title"><p>Questions</p><p>Among erroneous predictions, can you identify biases? Are these biases explained by the training data? Are these biases problematic in the problem selected?</p></blockquote><p>Now you know the elementary steps to train and test a machine learning model, you can try the same process on another dataset. The next section will teach you how to conduct the same steps using a programming langage (Python) and dedicated ML libraries.</p><h2 id="train-your-model-in-python"> <a href="#train-your-model-in-python" class="anchor-heading" aria-labelledby="train-your-model-in-python"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Train your model in Python</h2><p>In this section, you will learn how to train and test a machine learning model using Python and dedicated ML libraries. We recommand you to install Python via <a href="https://www.anaconda.com/download">Anaconda</a>. This way, you will also have jupyter notebook installed, which is a digital notebook that allows you to write and execute Python code in isolated cells. This way you can follow a step-by-step tutorial and execute the code at each step to see the results. You will also need yo install the following libraries: numpy, tensorflow, keras, matplotlib, and seaborn. You can install them using the following command in your terminal:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>numpy tensorflow keras matplotlib seaborn
</code></pre></div></div><p>The tutorial located in the file <code class="language-plaintext highlighter-rouge">ml-python-tutorial.ipynb</code> on the github repository of the course:</p><p><a href="https://github.com/aica-wavelab/aica-project-workshop/tree/main/1_introduction/ml-vision-python" class="btn" target="_blank">Python tutorial</a></p><p>The end of the tutorial also explains how to import a model trained in the Marcelle application and use it in Python.</p><h2 id="create-your-own-interactive-ml-web-application"> <a href="#create-your-own-interactive-ml-web-application" class="anchor-heading" aria-labelledby="create-your-own-interactive-ml-web-application"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Create your own interactive ML web application</h2><p>The interactive applications you used were programmed using Marcelle. <a href="https://marcelle.dev/">Marcelle</a> is a modular open source toolkit for programming interactive machine learning applications. Marcelle is built around components embedding computation and interaction that can be composed to form reactive machine learning pipelines and custom user interfaces. This architecture enables rapid prototyping and extension. Marcelle can be used to build interfaces to Python scripts, and it provides flexible data stores to facilitate collaboration between machine learning experts, designers and end users.</p><p>If you want to learn how to create your own interactive machine learning application, please read the <a href="https://marcelle.dev/guide/">introduction</a> and follow the tutorial on the Marcelle website:</p><p><a href="https://marcelle.dev/guide/getting-started.html" class="btn" target="_blank">Marcelle tutorial</a></p></main><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><div class="logo-container"><footer> <img src="/assets/images/logos/hm_logo.png" alt="Logo HM"> <img src="/assets/images/logos/mucdai_logo.jpg" alt="Logo MUC.DAI"> <img src="/assets/images/logos/hmtm_logo.png" alt="Logo HMTM"> <img src="/assets/images/logos/wavelab_logo.jpg" alt="Logo Wavelab"> <img src="/assets/images/logos/bidt_logo.png" alt="Logo BIDT"></footer></div><style> .logo-container img { filter: grayscale(100%); width: 100px; margin-right: 50px; } .logo-container img:last-child { margin-right: 0; }</style><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.6/dist/mermaid.min.js"></script> <script> var config = {} ; mermaid.initialize(config); window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid')); </script>
